import pandas as pd
import psycopg2
from sklearn.ensemble import IsolationForest
from sklearn.preprocessing import MinMaxScaler

def run_detection():
    conn = psycopg2.connect(
        dbname="anomaly_db",
        user="postgres",
        password="nazar",
        host="localhost",
        port="5432"
    )

    df = pd.read_sql_query("SELECT * FROM query_logs", conn)

    if len(df) < 5:
        print("âš ï¸ ÐÐµÐ´Ð¾ÑÑ‚Ð°Ñ‚Ð½ÑŒÐ¾ Ð´Ð°Ð½Ð¸Ñ… Ð´Ð»Ñ Ð°Ð½Ð°Ð»Ñ–Ð·Ñƒ (Ð¼ÐµÐ½ÑˆÐµ 5 Ð·Ð°Ð¿Ð¸ÑÑ–Ð²).")
        conn.close()
        return

    features = df[['affected_rows', 'execution_time_ms']].copy()
    scaler = MinMaxScaler()
    X_scaled = scaler.fit_transform(features)

    model = IsolationForest(contamination=0.15, random_state=42)
    df['anomaly'] = model.fit_predict(X_scaled).astype(bool)
    df['anomaly'] = ~df['anomaly']  # 1 â†’ False, -1 â†’ True

    cursor = conn.cursor()
    for _, row in df.iterrows():
        cursor.execute(
            "UPDATE query_logs SET is_anomaly = %s WHERE id = %s",
            (row['anomaly'], row['id'])
        )
    conn.commit()
    cursor.close()
    conn.close()

    detected = df[df['anomaly']]
    print(f"ðŸ§  ÐÐ½Ð¾Ð¼Ð°Ð»Ñ–Ð¹ Ð·Ð½Ð°Ð¹Ð´ÐµÐ½Ð¾: {len(detected)}")
    for _, row in detected.iterrows():
        print(f"âš ï¸ ID={row['id']} | {row['user_id']} {row['query_type']} [{row['affected_rows']} Ñ€ÑÐ´ÐºÑ–Ð², {row['execution_time_ms']} Ð¼Ñ]")

if __name__ == "__main__":
    run_detection()
